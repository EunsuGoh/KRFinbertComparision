from transformers import AutoTokenizer, AutoModel
import torch
import faiss
import numpy as np
import pandas as pd
import os
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

# âœ… ëª¨ë¸ ì„¤ì •
models = {
    "FinBERT-KR": "snunlp/KR-FinBert-SC",
    "Kakao DEBERTa": "kakaobank/kf-deberta-base"
}

# âœ… í† í¬ë‚˜ì´ì € & ëª¨ë¸ ë¡œë“œ
tokenizers = {name: AutoTokenizer.from_pretrained(model) for name, model in models.items()}
models = {name: AutoModel.from_pretrained(model) for name, model in models.items()}

# âœ… FAQ ë°ì´í„° ë¡œë“œ
faq_file = "./faq.xlsx"  # FAQ íŒŒì¼ ê²½ë¡œ
df = pd.read_excel(faq_file)
questions = df["Question"].tolist()

# âœ… ì„ë² ë”© í•¨ìˆ˜ (Mean Pooling ì ìš©)
def get_embedding(model, tokenizer, text):
    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512)
    with torch.no_grad():
        outputs = model(**inputs)
    embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()
    return embedding / np.linalg.norm(embedding)  # ì •ê·œí™”í•˜ì—¬ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ ë³€ê²½

# âœ… ëª¨ë“  ì§ˆë¬¸ ë²¡í„°í™”
embeddings = {name: [] for name in models.keys()}

for model_name, model in models.items():
    tokenizer = tokenizers[model_name]
    print(f"ğŸ”¹ {model_name} ì„ë² ë”© ìƒì„± ì¤‘...")
    
    for question in questions:
        emb = get_embedding(model, tokenizer, question)
        embeddings[model_name].append(emb)
    
    embeddings[model_name] = np.array(embeddings[model_name])

# âœ… FAISS ë²¡í„° DB ìƒì„± (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ ë³€ê²½)
index_faiss = {name: faiss.IndexFlatIP(768) for name in models.keys()}  # Inner Product ê¸°ë°˜ ì¸ë±ìŠ¤ ìƒì„±

for model_name in models.keys():
    index_faiss[model_name].add(embeddings[model_name])

print("âœ… FAISS ë²¡í„° DB ì €ì¥ ì™„ë£Œ!")

# âœ… ìœ ì‚¬ ì§ˆë¬¸ ê²€ìƒ‰ í•¨ìˆ˜ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì ìš©)
def search_similar(model_name, query, top_k=5):
    tokenizer = tokenizers[model_name]
    model = models[model_name]
    
    query_vec = get_embedding(model, tokenizer, query).reshape(1, -1)  # ì •ê·œí™” í¬í•¨
    D, I = index_faiss[model_name].search(query_vec, top_k)  # ê±°ë¦¬(D), ì¸ë±ìŠ¤(I) ë°˜í™˜
    
    print(f"\nğŸ” {model_name} ê²€ìƒ‰ ê²°ê³¼:")
    for i, idx in enumerate(I[0]):
        print(f"{i+1}. {questions[idx]} (ìœ ì‚¬ë„ ì ìˆ˜: {D[0][i]:.4f})")

# âœ… ì—¬ëŸ¬ ê°œì˜ ì¿¼ë¦¬ì— ëŒ€í•´ ê²€ìƒ‰ ìˆ˜í–‰
def batch_search(queries, model_name, top_k=3):
    print(f"\nğŸš€ [{model_name}] ëª¨ë¸ ê²€ìƒ‰ ê²°ê³¼ ë¹„êµ\n" + "="*50)
    
    for i, query in enumerate(queries):
        print(f"\nğŸ” í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ {i+1}: {query}")
        search_similar(model_name, query, top_k=top_k)
        print("-"*50)

# # âœ… í…ŒìŠ¤íŠ¸ ì§ˆë¬¸
# test_queries = [
#     "ì¸í„°ë„· ë±…í‚¹ ë¹„ë°€ë²ˆí˜¸ë¥¼ ë³€ê²½í•˜ë ¤ë©´ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?",
#     "í‡´ì§ì—°ê¸ˆ ê³„ì¢Œì—ì„œ ì¶œê¸ˆí•  ìˆ˜ ìˆë‚˜ìš”?",
#     "ìë™ì´ì²´ ì„¤ì •ì„ ë³€ê²½í•˜ê³  ì‹¶ì€ë° ì–´ë””ì„œ í•˜ë‚˜ìš”?",
#     "ì£¼ì‹ ê³„ì¢Œë¥¼ ê°œì„¤í•˜ë ¤ë©´ ì–´ë–¤ ì„œë¥˜ê°€ í•„ìš”í•œê°€ìš”?",
#     "ì‹ ìš©ì¹´ë“œ í•œë„ë¥¼ ìƒí–¥ ì¡°ì •í•˜ëŠ” ë°©ë²•ì´ ê¶ê¸ˆí•©ë‹ˆë‹¤.",
#     "ì •ê¸°ì˜ˆê¸ˆ ê¸ˆë¦¬ë¥¼ í™•ì¸í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.",
#     "ëª¨ë°”ì¼ ì•±ì—ì„œ ëŒ€ì¶œ ì‹ ì²­ì´ ê°€ëŠ¥í•œê°€ìš”?",
#     "IRP ê³„ì¢Œì—ì„œ ë‹¤ë¥¸ ê³„ì¢Œë¡œ ì´ì²´í•  ìˆ˜ ìˆë‚˜ìš”?",
#     "í•´ì™¸ ê²°ì œ ì‹œ ì ìš©ë˜ëŠ” í™˜ìœ¨ì€ ì–´ë–»ê²Œ ê²°ì •ë˜ë‚˜ìš”?",
#     "ìŠ¤ë§ˆíŠ¸í°ì—ì„œ ê³µì¸ì¸ì¦ì„œë¥¼ ë“±ë¡í•˜ëŠ” ë°©ë²•ì„ ì•Œê³  ì‹¶ì–´ìš”."
# ]

# # âœ… ë‘ ëª¨ë¸ì— ëŒ€í•´ ë¹„êµ ì‹¤í–‰
# batch_search(test_queries, "FinBERT-KR")
# batch_search(test_queries, "Kakao DEBERTa")

# âœ… í…ŒìŠ¤íŠ¸: ë‹¨ì¼ì¼ ì§ˆë¬¸ ê²€ìƒ‰
test_query = "IRPê°€ ë­ì—ìš”?"
print(f"ğŸ” í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: {test_query}")
search_similar("FinBERT-KR", test_query)
search_similar("Kakao DEBERTa", test_query)
